{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multilayer Perceptron Example\n",
    "\n",
    "MNIST dataset\n",
    "\n",
    "* 60K grayscale images (28x28)\n",
    "* Picture of a digit plus label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import os, time, shutil\n",
    "import zipfile, os\n",
    "from gluoncv.utils import download\n",
    "\n",
    "from mxnet import gluon, image, init, nd\n",
    "from mxnet import autograd as ag\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "from gluoncv.utils import makedirs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NDArray\n",
    "\n",
    "* N Dimensional array or Tensor\n",
    "* Identified by data type, shape\n",
    "* MXNetâ€™s primary tool for storing and transforming data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a 2D Tensor\n",
    "x = nd.array(((1, 2, 3), (5, 6, 7)))\n",
    "\n",
    "# 2x3 tensor with random data\n",
    "y = nd.random.uniform(low=-1, high=1, shape=(2,3))\n",
    "\n",
    "print (x.shape, x.size, x.dtype, x.context)\n",
    "\n",
    "# matrix multiplication\n",
    "print (nd.dot(x, y.T))\n",
    "\n",
    "# convert to numpy\n",
    "a = x.asnumpy()\n",
    "print (type(a), a)\n",
    "\n",
    "# convert back to NDArray\n",
    "nd.array(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Automatic differentiation with autograd\n",
    "\n",
    "* Goal: minimize a loss function.\n",
    "* How?\n",
    "    1. compute the gradient of the loss with respect to weights\n",
    "    2. update the weights accordingly\n",
    "* autograd package expedites this work by automatically calculating derivatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Differentiate\n",
    "\n",
    "$f(x) = 2 x^2$ \n",
    "\n",
    "with respect to parameter $x$.\n",
    "\n",
    "$y=2x^2$  \n",
    "\n",
    "$\\frac{dy}{dx} = 4x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "x = nd.array([[1, 2], [3, 4]])\n",
    "\n",
    "x.attach_grad()\n",
    "\n",
    "def f(x):\n",
    "    return 2 * x**2\n",
    "\n",
    "with ag.record():\n",
    "    y = f(x)\n",
    "\n",
    "print (x, y)\n",
    "\n",
    "y.backward()\n",
    "\n",
    "x, x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count\n",
    "\n",
    "# number of CPUs avalaible\n",
    "CPU_COUNT = cpu_count()\n",
    "\n",
    "num_gpu_range = mx.test_utils.list_gpus()\n",
    "\n",
    "# set context for training or inference in future\n",
    "ctx = [mx.gpu(i) for i in num_gpu_range] \\\n",
    "if num_gpu_range.stop > num_gpu_range.start else [mx.cpu()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Handwritten digits dataset\n",
    "\n",
    "* Grayscale: one byte for color channel\n",
    "* Input data is `(batch_size, 1, 28, 28)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dataset, DataLoader and Transforms\n",
    "[Dataset](https://mxnet.incubator.apache.org/api/python/gluon/data.html#mxnet.gluon.data.Dataset) - used to represent collection of data.  \n",
    "[DataLoader](https://mxnet.incubator.apache.org/api/python/gluon/data.html#mxnet.gluon.data.DataLoader) - mini-batches of data from Dataset, iterator interface, can load data in parallel.  \n",
    "[Transforms](https://mxnet.incubator.apache.org/api/python/gluon/data.html#vision-transforms) - Transformations that can applied on data for augmentation, multiple transforms can composed to apply sequentially on the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "# Load training/test data\n",
    "train_dataset = gluon.data.vision.MNIST(train=True).transform_first(transforms.ToTensor())\n",
    "# data loader to traverse the dataset in batches.\n",
    "train_data = gluon.data.DataLoader(train_dataset, \n",
    "                                   batch_size=batch_size,\n",
    "                                   shuffle=True, \n",
    "                                   num_workers=CPU_COUNT)\n",
    "\n",
    "val_dataset = gluon.data.vision.MNIST(train=False).transform_first(transforms.ToTensor())\n",
    "val_data = gluon.data.DataLoader(val_dataset, \n",
    "                                 batch_size=batch_size, num_workers=CPU_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(train_dataset[i][0][0].asnumpy(), cmap='Greys_r')\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "print('label: %s' % ' '.join([str(train_dataset[i][1]) for i in range(10)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data shape\n",
    "\n",
    "* Image batches are commonly represented by a shape (batch_size, num_channels, width, height). \n",
    "* For the MNIST dataset, the shape of input is (batch_size, 1, 28, 28)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "data_shape = None\n",
    "label_shape = None\n",
    "for X_batch, y_batch in train_data:\n",
    "    print(\"X_batch has shape {}, and y_batch has shape {}\".format(X_batch.shape, y_batch.shape))\n",
    "    data_shape = X_batch.shape\n",
    "    label_shape = y_batch.shape\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Define the network\n",
    "\n",
    "A Multi-Layer Perceptron with 3 dense/fully-connected layers.\n",
    "\n",
    "Gluon Block - Base class for all neural network layers and models.\n",
    "* A layer is a block\n",
    "* Multiple layers together can make a block\n",
    "* Nested blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deep Learning Programming Styles: Imperative vs  Symbolic\n",
    "\n",
    "Imperative style:\n",
    "* Tell the machine \"how\" to do it\n",
    "* Changes the program state\n",
    "\n",
    "Symbolic/declarative style:\n",
    "* Tell the machine \"what\" to do\n",
    "* Build the structure and elements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Example (Ref: http://latentflip.com/imperative-vs-declarative)\n",
    "Declarative: \n",
    "\n",
    "```SELECT * from dogs INNER JOIN owners WHERE dogs.owner_id = owners.id```\n",
    "\n",
    "Imperative:\n",
    "\n",
    "```\n",
    "//dogs = [{name: 'Fido', owner_id: 1}, {...}, ... ]\n",
    "//owners = [{id: 1, name: 'Bob'}, {...}, ...]\n",
    "\n",
    "var dogsWithOwners = []\n",
    "var dog, owner\n",
    "\n",
    "for(var di=0; di < dogs.length; di++) {\n",
    "  dog = dogs[di]\n",
    "\n",
    "  for(var oi=0; oi < owners.length; oi++) {\n",
    "    owner = owners[oi]\n",
    "    if (owner && dog.owner_id == owner.id) {\n",
    "      dogsWithOwners.push({\n",
    "        dog: dog,\n",
    "        owner: owner\n",
    "      })\n",
    "    }\n",
    "  }}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### HybridBlock\n",
    "\n",
    "* Gluon introduces hybrid programming through HybridBlock. \n",
    "* Combines declarative programming and imperative programming. \n",
    "* Users can quickly develop and debug models with imperative programming and switch to efficient declarative execution by simply calling: HybridBlock.hybridize()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "net = nn.HybridSequential()\n",
    "\n",
    "with net.name_scope():\n",
    "    net.add(nn.Dense(128, activation='relu'))\n",
    "    net.add(nn.Dense(64, activation='relu'))\n",
    "    net.add(nn.Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "net.hybridize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Visualize network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "x = mx.sym.var('data')\n",
    "sym = net(x)\n",
    "mx.viz.plot_network(sym, \\\n",
    "                    node_attrs={\"shape\":\"oval\",\"fixedsize\":\"false\"}, \\\n",
    "                    shape={\"data\": data_shape})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Initialize parameters and optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# initialize network parameters\n",
    "# Xavier initialization - avoid vanishing/exploding gradients\n",
    "# Gaussian distribution with zero mean and a suitable variance\n",
    "net.initialize(mx.init.Xavier(), ctx=ctx)\n",
    "\n",
    "# Trainer applies an Optimizer on a set of Parameters\n",
    "# Takes the parameters to be optimized, optimizer to use, and\n",
    "# optimizer params as arguments\n",
    "trainer = gluon.Trainer(net.collect_params(),\n",
    "                        'sgd',\n",
    "                        {'learning_rate': 0.02})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# define accuracy metric\n",
    "metric = mx.metric.Accuracy()\n",
    "\n",
    "# define loss function\n",
    "L = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# validation loop\n",
    "def test(net, val_data, ctx):\n",
    "    metric = mx.metric.Accuracy()\n",
    "    for i, batch in enumerate(val_data):\n",
    "        # Splits data into `len(ctx_list)` slices along `batch_axis` and loads\n",
    "        # each slice to one context in `ctx_list`\n",
    "        data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        # forward pass\n",
    "        outputs = [net(X) for X in data]\n",
    "        metric.update(label, outputs)\n",
    "\n",
    "    return metric.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "num_batch = len(train_data)\n",
    "epochs = 10\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    tic = time.time()\n",
    "    train_loss = 0\n",
    "    metric.reset()\n",
    "\n",
    "    for i, batch in enumerate(train_data):\n",
    "        # Splits data into `len(ctx_list)` slices along `batch_axis` and loads\n",
    "        # each slice to one context in `ctx_list`\n",
    "        data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0, even_split=False)\n",
    "        # autograd records computation history to calculate gradients later. \n",
    "        with ag.record():\n",
    "            # pass each slice of data to the network's forward pass and collect output            \n",
    "            outputs = [net(X) for X in data]\n",
    "            # compute loss\n",
    "            loss = [L(yhat, y) for yhat, y in zip(outputs, label)]\n",
    "        # for each loss in the batch, backpropagate            \n",
    "        for l in loss:\n",
    "            l.backward()\n",
    "        # Makes one step of parameter update.\n",
    "        trainer.step(batch_size)\n",
    "        # loss over the batch\n",
    "        train_loss += sum([l.mean().asscalar() for l in loss]) / len(loss)\n",
    "\n",
    "        # update metric\n",
    "        metric.update(label, outputs)\n",
    "\n",
    "    # metrics for the epoch\n",
    "    _, train_acc = metric.get()\n",
    "    train_loss /= num_batch\n",
    "    \n",
    "    _, val_acc = test(net, val_data, ctx)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print('[Epoch %d] Train-acc: %.3f, loss: %.3f | Val-acc: %.3f | time: %.1f' %\n",
    "             (epoch, train_acc, train_loss, val_acc, time.time() - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Plot Training and Validataion Loss/Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f = plt.figure(figsize=(12,6))\n",
    "fg1 = f.add_subplot(121)\n",
    "fg2 = f.add_subplot(122)\n",
    "\n",
    "fg1.set_xlabel('epoch',fontsize=14)  \n",
    "fg1.set_title('Loss over Training')\n",
    "fg1.grid(True, which=\"both\")\n",
    "fg1.plot(range(epochs), train_losses)\n",
    "\n",
    "fg2.set_title('Comparing accuracy')\n",
    "fg2.set_xlabel('epoch', fontsize=14)\n",
    "fg2.grid(True, which=\"both\")\n",
    "\n",
    "p1, = fg2.plot(range(epochs), train_accuracies)\n",
    "p2, = fg2.plot(range(epochs), val_accuracies)\n",
    "fg2.legend([p1, p2], ['training accuracy', 'validation accuracy'],fontsize=14) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# evaluate the trained model by running predictions on validation dataset\n",
    "_, test_acc = test(net, val_data, ctx)\n",
    "print('[Finished] Test-acc: %.3f' % (test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Prediction\n",
    "\n",
    "* Also called _Inference_\n",
    "* Evaluate against unseen data\n",
    "* Ensure model is not overfit\n",
    "* We want models that generalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    idx = np.random.randint(1, 10000)\n",
    "    d = val_dataset[idx][0][0].asnumpy()\n",
    "    x  = (mx.nd.expand_dims(mx.nd.array(d), axis=0))\n",
    "    #forward pass\n",
    "    prediction = net(x.as_in_context(ctx[0]))\n",
    "    prediction = np.squeeze(prediction.asnumpy())\n",
    "    prediction = np.argmax(prediction)\n",
    "    print('prediction: %s, ground truth label: %s' % (prediction, val_dataset[idx][1]))\n",
    "    plt.imshow(d, cmap='Greys_r')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "net.export('gluon-mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "!ls ./gluon-mnist*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "display_name": "",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "name": "",
  "rise": {
   "shortcuts": {
    "down": "Down Arrow",
    "up": "Up Arrow"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
