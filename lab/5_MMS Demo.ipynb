{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MXNet Model Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This Notebook is borrowed from: https://github.com/TalkAI/facial-emotion-recognition-gluon/blob/master/notebooks/Gluon_FERPlus.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Install the required Packages locally\n",
    "\n",
    "We will need the PyPi packages listed below to test model server locally, and to perform image pre-processing prior to the model inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mYou are using pip version 10.0.1, however version 19.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "mxnet-model-server installed\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "scikit-learn installed\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "opencv-python installed\n"
     ]
    }
   ],
   "source": [
    "!pip install -q mxnet-model-server==1.0\n",
    "print('mxnet-model-server installed')\n",
    "!pip install -q scikit-image==0.13.0\n",
    "print('scikit-learn installed')\n",
    "!pip install -q opencv-python\n",
    "print('opencv-python installed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"input_type\": \"image/jpeg\", \n",
      "  \"inputs\": [\n",
      "    {\n",
      "      \"data_shape\": [1, 1, 64, 64], \n",
      "      \"data_name\": \"data\"\n",
      "    }\n",
      "  ], \n",
      "  \"outputs\": [\n",
      "    {\n",
      "      \"data_shape\": [1, 8],\n",
      "      \"data_name\": \"hybridsequential0_dense2_fwd\"\n",
      "    }\n",
      "  ], \n",
      "  \"output_type\": \"application/json\"\n",
      "}"
     ]
    }
   ],
   "source": [
    "# We define the model's input and output type and shape via signature.json\n",
    "# %cd /Users/kannanva/Documents/gbdc-mxnet-workshop/lab\n",
    "%cat ./model_archive_resources/signature.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n",
      "happiness\n",
      "surprise\n",
      "sadness\n",
      "anger\n",
      "disgust\n",
      "fear\n",
      "contempt"
     ]
    }
   ],
   "source": [
    "# We define the model's class label names via synset.txt\n",
    "%cat ./model_archive_resources/synset.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\").\n",
      "# You may not use this file except in compliance with the License.\n",
      "# A copy of the License is located at\n",
      "#     http://www.apache.org/licenses/LICENSE-2.0\n",
      "# or in the \"license\" file accompanying this file. This file is distributed\n",
      "# on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n",
      "# express or implied. See the License for the specific language governing\n",
      "# permissions and limitations under the License.\n",
      "\n",
      "import numpy as np\n",
      "from mxnet_model_service import MXNetModelService\n",
      "from mxnet_utils import image, ndarray\n",
      "from skimage import transform\n",
      "import mxnet as mx\n",
      "import cv2 as cv\n",
      "import logging\n",
      "\n",
      "# One time initialization of Haar Cascade Classifier to extract and crop out face\n",
      "face_detector = cv.CascadeClassifier('haarcascade_frontalface.xml')\n",
      "# Classifier parameter specifying how much the image size is reduced at each image scale\n",
      "scale_factor = 1.3\n",
      "# Classifier parameter how many neighbors each candidate rectangle should have to retain it\n",
      "min_neighbors = 5\n",
      "\n",
      "def crop_face(image):\n",
      "    \"\"\"Attempts to identify a face in the input image.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    image : array representing a BGR image\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    array\n",
      "        The cropped face, transformed to grayscale. If no face found returns None\n",
      "\n",
      "    \"\"\"\n",
      "    gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
      "    face_roi_list = face_detector.detectMultiScale(gray_image, scale_factor, min_neighbors)\n",
      "    \n",
      "    if (len(face_roi_list) > 0):\n",
      "        (x,y,w,h) = face_roi_list[0]\n",
      "        return gray_image[y:y+h,x:x+w]\n",
      "    else:\n",
      "        return None\n",
      "\n",
      "class FERService(MXNetModelService):\n",
      "    \"\"\"\n",
      "    Defines custom pre and post processing for the Facial Emotion Recognition model\n",
      "    \"\"\"\n",
      "\n",
      "    def preprocess(self, request):\n",
      "        \"\"\"\n",
      "        Pre-process requests by attempting to extract face image, and transforing to fit the model's input\n",
      "        Parameters\n",
      "        ----------\n",
      "        data : list of input images\n",
      "            Raw inputs from request.\n",
      "        Returns\n",
      "        -------\n",
      "        list of NDArray\n",
      "            Processed images in the model's expected input shape\n",
      "        \"\"\"\n",
      "        img_list = []\n",
      "\n",
      "        for idx, data in enumerate(request):\n",
      "            param_name = self.signature['inputs'][idx]['data_name']\n",
      "            input_shape = self.signature['inputs'][idx]['data_shape']\n",
      "            img = data.get(param_name)\n",
      "            if img is None:\n",
      "                img = data.get(\"body\")\n",
      "\n",
      "            if img is None:\n",
      "                img = data.get(\"data\")\n",
      "\n",
      "            if img is None or len(img) == 0:\n",
      "                self.error = \"Empty image input\"\n",
      "                return None\n",
      "\n",
      "            # We are assuming input shape is NCHW\n",
      "            [h, w] = input_shape[2:]\n",
      "\n",
      "            try:\n",
      "                img_arr = image.read(img)\n",
      "            except Exception as e:\n",
      "                logging.warn(e, exc_info=True)\n",
      "                self.error = \"Corrupted image input\"\n",
      "                return None\n",
      "\n",
      "            face = crop_face(img_arr.asnumpy())\n",
      "            if (face is not None):\n",
      "                face = transform.resize(face, (h,w))            \n",
      "            # If no face identified - use the entire input image\n",
      "            else:\n",
      "                face = cv.cvtColor(img_arr, cv.COLOR_BGR2GRAY)\n",
      "            img_arr = np.resize(face, input_shape)\n",
      "            img_list.append(mx.nd.array(img_arr))\n",
      "        return img_list\n",
      "\n",
      "    def postprocess(self, data):\n",
      "        response = []\n",
      "        for d in data:\n",
      "            inference_result = d.softmax().asnumpy()\n",
      "        for idx, label in enumerate(self.labels):\n",
      "            response.append({label: float(inference_result[0][idx])})\n",
      "        return [response]\n",
      "\n",
      "\n",
      "_service = FERService()\n",
      "\n",
      "\n",
      "def handle(data, context):\n",
      "    if not _service.initialized:\n",
      "        _service.initialize(context)\n",
      "\n",
      "    if data is None:\n",
      "        return None\n",
      "\n",
      "    return _service.handle(data, context)\n"
     ]
    }
   ],
   "source": [
    "# And lastly, we define custom code for request handling via python code other auxiliary files\n",
    "%cat ./model_archive_resources/fer_service.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/ferplus\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 33.4M  100 33.4M    0     0  12.7M      0  0:00:02  0:00:02 --:--:-- 12.7M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 16867  100 16867    0     0  44859      0 --:--:-- --:--:-- --:--:-- 44859\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ~/SageMaker/ferplus\n",
    "%pushd ~/SageMaker/ferplus\n",
    "!curl -O https://s3.amazonaws.com/mxnet-demo-models/models/fer/gluon_ferplus-0000.params\n",
    "!curl -O https://s3.amazonaws.com/mxnet-demo-models/models/fer/gluon_ferplus-symbol.json\n",
    "\n",
    "!mv ~/SageMaker/ferplus/gluon_ferplus-0000.params ~/SageMaker/ferplus/ferplus-0000.params\n",
    "!mv ~/SageMaker/ferplus/gluon_ferplus-symbol.json ~/SageMaker/ferplus/ferplus-symbol.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker\n",
      "popd -> ~/SageMaker\n"
     ]
    }
   ],
   "source": [
    "%popd\n",
    "%cp -r ./model_archive_resources/* ~/SageMaker/ferplus/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/ferplus\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['~/SageMaker']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pushd ~/SageMaker/ferplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 ec2-user ec2-user 3956 Jan 24 07:03 ./fer_service.py\n"
     ]
    }
   ],
   "source": [
    "ls -al ./fer_service.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR - %s already exists.\n",
      "Please specify --force/-f option to overwrite the model archive output file.\n",
      "See -h/--help for more details./home/ec2-user/SageMaker/ferplus.mar\n"
     ]
    }
   ],
   "source": [
    "# Let's package everything up into a Model Archive bundle\n",
    "!model-archiver --model-name ferplus --handler fer_service:handle --model-path /home/ec2-user/SageMaker/ferplus --export-path /home/ec2-user/SageMaker/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access ferplus.mar: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls -l ferplus.mar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Spawning a new process to run the server\n",
    "import subprocess as sp\n",
    "server = sp.Popen(\"mxnet-model-server --start --model-store /home/ec2-user/SageMaker/ --models ferplus=ferplus.mar\", shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17090"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server.pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"status\": \"Healthy\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Check out the health endpoint\n",
    "!curl http://localhost:8080/ping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ferplus-0000.params    haarcascade_frontalface.xml  mxnet_utils\n",
      "ferplus-symbol.json    logs\t\t\t    signature.json\n",
      "fer_service.py\t       model_handler.py\t\t    synset.txt\n",
      "gluon_base_service.py  mxnet_model_service.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker\n",
      "popd -> ~/SageMaker\n"
     ]
    }
   ],
   "source": [
    "%popd\n",
    "test_image='happy.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f93d1292710>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "img = Image.open(test_image)\n",
    "imshow(np.asarray(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"neutral\": 0.3884313404560089\n",
      "  },\n",
      "  {\n",
      "    \"happiness\": 0.5333355069160461\n",
      "  },\n",
      "  {\n",
      "    \"surprise\": 0.002492635976523161\n",
      "  },\n",
      "  {\n",
      "    \"sadness\": 0.05850818008184433\n",
      "  },\n",
      "  {\n",
      "    \"anger\": 0.00885448046028614\n",
      "  },\n",
      "  {\n",
      "    \"disgust\": 0.0009527787915430963\n",
      "  },\n",
      "  {\n",
      "    \"fear\": 0.00076449871994555\n",
      "  },\n",
      "  {\n",
      "    \"contempt\": 0.006660618353635073\n",
      "  }\n",
      "]"
     ]
    }
   ],
   "source": [
    "!curl -X POST http://localhost:8080/predictions/ferplus -F \"data=@$test_image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Lastly, we'll terminate the server\n",
    "server.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
